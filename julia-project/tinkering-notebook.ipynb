{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBN Structure Inference\n",
    "\n",
    "The idea is to infer a posterior for the *structure* of a Dynamic Bayesian Network (DBN), given some data.\n",
    "\n",
    "We formulate this task with the following model:\n",
    "\n",
    "$$ P(G | X) \\propto P(X | G) \\cdot P(G) $$\n",
    "\n",
    "* $P(G)$ is a prior distribution over DBN structures. We'll assume it has the form\n",
    "$$P(G) \\propto \\exp \\left( -\\lambda |G \\setminus G^\\prime| \\right)$$\n",
    "where $|G \\setminus G^\\prime|$ denotes the number of edges in the graph, which are not present in some reference graph $G^\\prime$.\n",
    "* $P(X | G)$ is the marginal likelihood of the DBN structure. That is, it's the likelihood of the DBN after the network parameters have been integrated out -- it scores network *structure*. \n",
    "* If we assume some reasonable priors for network parameters, $P(X|G)$ can be obtained in closed form. In this work, we'll use the following marginal likelihood:\n",
    "    \n",
    "    $$P(X | G) \\propto \\prod_{i=1}^p (1 + n)^{-(2^{|\\pi(i)|} - 1)/2} \\left( X_i^{+ T} X_i^+ - \\frac{n}{n+1} X_i^{+ T} B_i (B_i^T B_i)^{-1} B_i^T X_i^+ \\right)^{-\\frac{n}{2}}$$ \n",
    "    where $X$ and $B$ are matrices obtained from data; and $n$ is the total number of timesteps in the dataset. This marginal likelihood results from an empirical prior over the regression coefficients, and an improper ($\\propto 1/\\sigma^2$) prior for the regression \"noise\" variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data\n",
    "\n",
    "For now, we'll work with some data used by Hill et al. in their 2012 paper, _Bayesian Inference of Signaling Network Topology in a Cancer Cell Line_.\n",
    "\n",
    "It gives the differential phosphorylation levels of 20 proteins, in a cancer cell line perturbed by EGF. This is a well-studied signaling pathway; the goal is to produce a graph describing the dependencies between proteins in this pathway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I have confirmed that the ordering of proteins in `protein_vec` is identical to the ordering in the columns of `timeseries_data`. So we can depend on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Implement the graph prior distribution:\n",
    "\n",
    "$$P(G) \\propto \\exp \\left( -\\lambda |G \\setminus G^\\prime| \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the DBN's marginal distribution:\n",
    "\n",
    "$$P(X | G) \\propto \\prod_{i=1}^p (1 + n)^{-(2^{|\\pi(i)|} - 1)/2} \\left( X_i^{+ T} X_i^+ - \\frac{n}{n+1} X_i^{+ T} B_i (B_i^T B_i)^{-1} B_i^T X_i^+ \\right)^{-\\frac{n}{2}}$$\n",
    "\n",
    "Some things to note:\n",
    "* We're kind of shoe-horning this marginal likelihood into Gen. The probabilistic programming ethos entails modeling the entire data-generating process. This ought to provide better performance during inference, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A BUNCH OF HELPER FUNCTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE MARGINAL LIKELIHOOD DISTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "### Metropolis-Hastings over directed graphs\n",
    "\n",
    "Proposal distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Involution function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our inference program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING THE NEW MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using GLMNet\n",
    "include(\"PSDiGraph.jl\")\n",
    "using .PSDiGraphs\n",
    "include(\"dbn_preprocessing.jl\")\n",
    "include(\"dbn_models.jl\")\n",
    "include(\"dbn_proposals.jl\")\n",
    "include(\"dbn_inference.jl\")\n",
    "using PyPlot\n",
    "using Profile\n",
    "using ProfileView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_data_path = \"data/mukherjee_data.csv\"\n",
    "protein_names_path = \"data/protein_names.csv\"\n",
    "reference_adj_path = \"data/prior_graph.csv\"\n",
    "timesteps_path = \"data/time.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(timeseries_vec, protein_vec, ref_adj, timesteps) = hill_2012_preprocess(timeseries_data_path, \n",
    "                                                                         protein_names_path, \n",
    "                                                                         reference_adj_path, \n",
    "                                                                         timesteps_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen.load_generated_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clear_caches()\n",
    "regression_deg = 1\n",
    "lambda_max = 10.0\n",
    "n_samples = 200\n",
    "fixed_lambda = 3.0\n",
    "burnin = 100\n",
    "thinning = 10\n",
    "lambda_step = 0.3\n",
    "V = length(protein_vec)\n",
    "t = 0.4\n",
    "\n",
    "results, acc = dbn_mcmc_inference(ref_adj, timeseries_vec, regression_deg, lambda_max,\n",
    "                                  n_samples, burnin, thinning, \n",
    "                                  ps_smart_swp_update_loop,\n",
    "                                  update_results_z_lambda!, #TODO\n",
    "                                  (lambda_step,),\n",
    "                                  ((V, t), V));\n",
    "                                  #update_lambda=false,\n",
    "                                  #fixed_lambda=fixed_lambda,\n",
    "                                  #track_acceptance=true,\n",
    "                                  #update_acceptances! =update_acc_z_lambda!) # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(results[2])\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typeof(update_results_z_lambda!) <: Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matshow(transpose(ref_adj), cmap=\"Greys\")\n",
    "# matshow(transpose(edge_posterior), cmap=\"Greys\")\n",
    "# transpose(edge_posterior)[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hill_result = convert(Matrix{Float64}, CSV.read(\"data/edge_prob_matrix.csv\"))\n",
    "# matshow(hill_result, cmap=\"Greys\")\n",
    "# hill_result[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dict(\"cat\" => [1;2;3;], \"dog\" => Dict(\"woof\" => [4;5;6], \"bow-wow\" => [\"ruff\";nothing]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON.json(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"temp.json\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(f, JSON.json(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs2.([-1.0; 0.0; 1.0] .- 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof([[[1.0];[[3.0;4.0]]];[5.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myreduce (generic function with 2 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myreduce(f::Function, vec::Vector{T}) where {T<:Number}\n",
    "    return f(vec)\n",
    "end\n",
    "\n",
    "function myreduce(f::Function, vec::Vector{Vector{T}}) where T\n",
    "    return [myreduce(f, [item[field] for item in vec]) for (field, _) in enumerate(vec[1])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_variance"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute the sample averages over a vector of MCMC results\n",
    "\"\"\"\n",
    "function sample_average(sample_vec::Vector)\n",
    "    return myreduce(v->1.0*sum(v)/length(v), sample_vec)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Compute the sample variances over a vector of MCMC results\n",
    "\"\"\"\n",
    "function sample_variance(sample_vec::Vector)\n",
    "    mu = sample_average(sample_vec)\n",
    "    return myreduce(x->sum(abs2.(x))/length(sample_vec), sample_vec .- mu)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mybinop"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Perform a binary operation f(vec1, vec2) on arbitrarily nested vectors\n",
    "(assume identical structure between vec1 and vec2, though)\n",
    "\"\"\"\n",
    "function mybinop(f::Function, vec1::Vector{T}, vec2::Vector{U}) where {T,U}\n",
    "    return [mybinop(f, v1i, vec2[i]) for (i,v1i) in enumerate(vec1)]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Perform a binary operation f(vec1, vec2) on arbitrarily nested vectors\n",
    "(assume identical structure between vec1 and vec2, though)\n",
    "\"\"\"\n",
    "function mybinop(f::Function, v1::T, v2::U) where {T<:Number,U<:Number}\n",
    "    return f(v1, v2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_variance"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute the sample variances over a vector of MCMC results\n",
    "\"\"\"\n",
    "function sample_variance(sample_vec::Vector)\n",
    "    mu = sample_average(sample_vec)\n",
    "    centered = [mybinop(-, s, mu) for s in sample_vec]\n",
    "    return myreduce(x->sum(abs2.(x))/(length(centered)-1.0), centered)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array{Array{Array{T,1} where T,1},1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{T,1} where T,1}:\n",
       " Array{Float64,1}[[2.5]]\n",
       " [1.0]                  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [[[[1.0]], [true]], [[[1.0]], [true]], [[[4.0]], [true]], [[[4.0]], [true]]]\n",
    "println(typeof(arr))\n",
    "sample_average(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{T,1} where T,1}:\n",
       " Array{Float64,1}[[3.0]]\n",
       " [0.0]                  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_variance(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
