{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBN Structure Inference\n",
    "\n",
    "The idea is to infer a posterior for the *structure* of a Dynamic Bayesian Network (DBN), given some data.\n",
    "\n",
    "We formulate this task with the following model:\n",
    "\n",
    "$$ P(G | X) \\propto P(X | G) \\cdot P(G) $$\n",
    "\n",
    "* $P(G)$ is a prior distribution over DBN structures. We'll assume it has the form\n",
    "$$P(G) \\propto \\exp \\left( -\\lambda |G \\setminus G^\\prime| \\right)$$\n",
    "where $|G \\setminus G^\\prime|$ denotes the number of edges in the graph, which are not present in some reference graph $G^\\prime$.\n",
    "* $P(X | G)$ is the marginal likelihood of the DBN structure. That is, it's the likelihood of the DBN after the network parameters have been integrated out -- it scores network *structure*. \n",
    "* If we assume some reasonable priors for network parameters, $P(X|G)$ can be obtained in closed form. In this work, we'll use the following marginal likelihood:\n",
    "    \n",
    "    $$P(X | G) \\propto \\prod_{i=1}^p (1 + n)^{-(2^{|\\pi(i)|} - 1)/2} \\left( X_i^{+ T} X_i^+ - \\frac{n}{n+1} X_i^{+ T} B_i (B_i^T B_i)^{-1} B_i^T X_i^+ \\right)^{-\\frac{n}{2}}$$ \n",
    "    where $X$ and $B$ are matrices obtained from data; and $n$ is the total number of timesteps in the dataset. This marginal likelihood results from an empirical prior over the regression coefficients, and an improper ($\\propto 1/\\sigma^2$) prior for the regression \"noise\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"DiGraph.jl\")\n",
    "using Gen\n",
    "using Plots\n",
    "Plots.pyplot()\n",
    "using .DiGraphs\n",
    "using LinearAlgebra\n",
    "using CSV\n",
    "using DataFrames\n",
    "using LRUCache\n",
    "using Combinatorics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data\n",
    "\n",
    "For now, we'll work with some data used by Hill et al. in their 2007 paper, _Bayesian Inference of Signaling Network Topology in a Cancer Cell Line_.\n",
    "\n",
    "It gives the differential phosphorylation levels of 20 proteins, in a cancer cell line perturbed by EGF. This is a well-studied signaling pathway; the goal is to produce a graph describing the dependencies between proteins in this pathway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_names = CSV.read(\"data/protein_names.csv\");\n",
    "protein_vec = convert(Matrix, protein_names)[:,1];\n",
    "protein_vec = [name[3:length(name)-2] for name in protein_vec]\n",
    "reference_adjacency = CSV.read(\"data/prior_graph.csv\");\n",
    "adj_mat = convert(Matrix, reference_adjacency);\n",
    "timesteps = CSV.read(\"data/time.csv\");\n",
    "timeseries_data = CSV.read(\"data/mukherjee_data.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I have confirmed that the ordering of proteins in `protein_vec` is identical to the ordering in the columns of `timeseries_data`. So we can depend on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timeseries_preprocess! (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function timeseries_preprocess!(timeseries_df)\n",
    "    timeseries_data.condition = [ split(s, \" \")[2] for s in timeseries_data[!, :Column1] ]\n",
    "    timeseries_data.time = [ parse(Float64, split(s, \" \")[4][2:end]) for s in timeseries_data[!, :Column1]]\n",
    "    timeseries_data.replicate = [tryparse(Int64, split(s, \" \")[6][2:end-1]) for s in timeseries_data[!, :Column1]]\n",
    "    \n",
    "    gp = DataFrames.groupby( timeseries_data, [:condition; :replicate])\n",
    "    ts_vec = [convert(Matrix, g)[:,2:end-3] for g in gp]\n",
    "    ts_vec = [convert(Matrix{Float64}, m) for m in ts_vec]\n",
    "    \n",
    "    return ts_vec\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_reference_graph(vertices::Vector{T}, reference_adj::Array{Int,2}) where T\n",
    "    dg = DiGraph{T}()\n",
    "    for i=1:size(reference_adj)[1]\n",
    "        for j=1:size(reference_adj)[2]\n",
    "            if reference_adj[i,j] == 1\n",
    "                add_edge!(dg, vertices[i], vertices[j])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return dg\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_dg = build_reference_graph(collect(1:length(protein_vec)), adj_mat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_vec = timeseries_preprocess!(timeseries_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Implement the graph prior distribution:\n",
    "\n",
    "$$P(G) \\propto \\exp \\left( -\\lambda |G \\setminus G^\\prime| \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct GraphPrior <: Gen.Distribution{DiGraph} end\n",
    "const graphprior = GraphPrior()\n",
    "\n",
    "Gen.random(gp::GraphPrior, lambda::Float64, reference_graph::DiGraph) = reference_graph\n",
    "\n",
    "function graph_edge_diff(g::DiGraph, g_ref::DiGraph)\n",
    "    e1 = Set([g.edges[i,:] for i=1:size(g.edges)[1]])\n",
    "    e_ref = Set([g_ref.edges[i,:] for i=1:size(g_ref.edges)[1]])\n",
    "    return length(setdiff(e1, e_ref))\n",
    "end\n",
    "    \n",
    "Gen.logpdf(gp::GraphPrior, graph::DiGraph, lambda::Float64, reference_graph::DiGraph) = -lambda * graph_edge_diff(graph, reference_graph)\n",
    "\n",
    "graphprior(lambda::Float64, reference_graph::DiGraph) = Gen.random(graphprior, lambda, reference_graph);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the DBN's marginal distribution:\n",
    "\n",
    "$$P(X | G) \\propto \\prod_{i=1}^p (1 + n)^{-(2^{|\\pi(i)|} - 1)/2} \\left( X_i^{+ T} X_i^+ - \\frac{n}{n+1} X_i^{+ T} B_i (B_i^T B_i)^{-1} B_i^T X_i^+ \\right)^{-\\frac{n}{2}}$$\n",
    "\n",
    "Some things to note:\n",
    "* We're kind of shoe-horning this marginal likelihood into Gen. The probabilistic programming ethos entails modeling the entire data-generating process. This ought to provide better performance during inference, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A BUNCH OF HELPER FUNCTIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_parent_vecs (generic function with 1 method)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a few levels of LRU caching to reduce redundant computation.\n",
    "const TENMB = 10000000\n",
    "\n",
    "# Top level: store computed log-marginal likelihoods: log P(x_i | parents(x_i))\n",
    "lp_cache = LRU{Vector{Int64}, Float64}(maxsize=TENMB, by=Base.summarysize)\n",
    "\n",
    "# Middle level: store the value of B inv(B^T B) B^T; \n",
    "# may be reused when different children have the same parents. \n",
    "B2invconj_cache = LRU{Vector{Int64},Array{Float64,2}}(maxsize=TENMB, by=Base.summarysize)\n",
    "\n",
    "# Bottom level: store B columns. B columns may be reused by different B matrices\n",
    "# (so caching may be useful). But the number of possible columns is\n",
    "# enormous, so an LRU policy is called for.\n",
    "B_col_cache = LRU{Vector{Int64},Vector{Float64}}(maxsize=10*TENMB, by=Base.summarysize)\n",
    "\n",
    "\n",
    "function compute_B_col(inds::Vector{Int64}, Xminus)\n",
    "    return prod(Xminus[:,inds], dims=2)[:,1]\n",
    "end\n",
    "\n",
    "\n",
    "function construct_B(parent_inds::Vector{Int64}, Xminus::Array{Float64,2}, deg_max::Int64)\n",
    "    \n",
    "    n_cols = sum([binomial(length(parent_inds), k) for k=1:deg_max])\n",
    "    B = zeros(size(Xminus)[1], n_cols)\n",
    "    \n",
    "    col = 1\n",
    "    for deg=1:deg_max\n",
    "        for comb in Combinatorics.combinations(parent_inds, deg)\n",
    "            B[:,col] = get!(B_col_cache, comb) do\n",
    "                return compute_B_col(comb, Xminus)  \n",
    "            end \n",
    "            col += 1\n",
    "        end\n",
    "    end\n",
    "    return B\n",
    "end\n",
    "\n",
    "\n",
    "function construct_B2invconj(parent_inds::Vector{Int64}, Xminus::Array{Float64,2}, deg_max::Int64)\n",
    "    if length(parent_inds) == 0\n",
    "        return Matrix{Float64}(I, size(Xminus)[1], size(Xminus)[1])\n",
    "    end\n",
    "    B = construct_B(parent_inds, Xminus, deg_max)\n",
    "    B2inv = LinearAlgebra.inv(LinearAlgebra.Symmetric(transpose(B) * B + 0.1*I))\n",
    "    return B * (B2inv * transpose(B))\n",
    "end\n",
    "\n",
    "\n",
    "function combine_X(X::Vector{Array{Float64,2}})\n",
    "    \n",
    "    len = sum([size(x)[1] - 1 for x in X])\n",
    "    wid = size(X[1])[2]\n",
    "    println(\"COMBINED X: (LEN=\", len,\",WID=\", wid,\")\")\n",
    "    Xminus = zeros(len, wid)\n",
    "    Xplus = zeros(len, wid)\n",
    "    \n",
    "    l_ind = 1\n",
    "    for x in X\n",
    "        r_ind = l_ind + size(x)[1] - 2\n",
    "        Xminus[l_ind:r_ind, :] = x[1:size(x)[1]-1, :]\n",
    "        Xplus[l_ind:r_ind, :] = x[2:size(x)[1], :]\n",
    "        l_ind = r_ind + 1\n",
    "    end\n",
    "\n",
    "    println(\"XMINUS: (LEN=\", size(Xminus)[1],\",WID=\", size(Xminus)[2],\")\")\n",
    "    println(\"XPLUS: (LEN=\", size(Xplus)[1],\",WID=\", size(Xplus)[2],\")\")\n",
    "    return Xminus, Xplus\n",
    "end\n",
    "\n",
    "\n",
    "function log_marg_lik(ind::Int64, parent_inds::Vector{Int64}, \n",
    "                      Xminus::Array{Float64,2}, Xplus::Array{Float64,2}, deg_max::Int64)\n",
    "\n",
    "    B2invconj = get!(B2invconj_cache, parent_inds) do\n",
    "        construct_B2invconj(parent_inds, Xminus, deg_max)\n",
    "    end\n",
    "    Xp = Xplus[:, ind] \n",
    "    n = size(Xplus)[1]\n",
    "    \n",
    "    #println(\"IND: \", ind, \"\\tPARENTS: \", parent_inds)\n",
    "    #println(\"XP^T XP = \", dot(Xp, Xp), \"\\tXp^T B2invconj Xp = \", (1.0*n/(n+1))*dot( Xp, B2invconj * Xp))\n",
    "    return -0.5*(2.0^length(parent_inds) - 1)*log(1.0 + n) - 0.5*n*log( dot(Xp,Xp) - (1.0*n/(n+1))*dot( Xp, B2invconj * Xp))   \n",
    "    \n",
    "end\n",
    "\n",
    "function get_parent_vecs(graph::DiGraph, vertices)\n",
    "    return [convert(Vector{Int64}, sort([indexin([n], vertices)[1] for n in in_neighbors(graph, v)])) for v in vertices]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE MARGINAL LIKELIHOOD DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gen.logpdf"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct DBNMarginal <: Gen.Distribution{Vector{Array{Float64,2}}} end\n",
    "const dbnmarginal = DBNMarginal()\n",
    "\n",
    "\"\"\"\n",
    "DBNMarginal's sampling method does nothing.\n",
    "In our inference task, the Xs will always be observed.\n",
    "\"\"\"\n",
    "Gen.random(dbnm::DBNMarginal, parents::Vector{Vector{T}}, Xminus::Array{Float64,2}, Xplus::Array{Float64,2}, deg_max::Int64) where T = [zeros(length(parents), length(Xminus))]\n",
    "\n",
    "dbnmarginal(parents, Xminus, Xplus, deg_max) = Gen.random(dbnmarginal, parents, Xminus, Xplus, deg_max)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DBNMarginal's log_pdf, in effect, returns a score for the \n",
    "network topology. We use a dictionary to cache precomputed terms of the sum.\n",
    "\"\"\"\n",
    "function Gen.logpdf(dbn::DBNMarginal, X::Vector{Array{Float64,2}}, \n",
    "                    parents::Vector{Vector{Int64}}, Xminus::Array{Float64,2}, Xplus::Array{Float64,2}, deg_max::Int64)\n",
    "    \n",
    "    lp = 0.0\n",
    "    for i=1:length(parents)\n",
    "        lp += get!(lp_cache, [[i]; parents[i]]) do\n",
    "           log_marg_lik(i, parents[i], Xminus, Xplus, deg_max) \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return lp\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement our overall model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getfield(Main, Symbol(\"##StaticGenFunction_full_model#439\"))(Dict{Symbol,Any}(), Dict{Symbol,Any}())"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@gen (static) function full_model(X::Vector{Array{Float64,2}}, reference_graph::DiGraph, deg_max::Int64)\n",
    "    \n",
    "    V = sort(collect(reference_graph.vertices))\n",
    "    lambda = @trace(Gen.gamma(1,1), :lambda)\n",
    "    \n",
    "    G = @trace(graphprior(lambda, reference_graph), :G)\n",
    "    \n",
    "    parent_vecs = get_parent_vecs(G, V)\n",
    "    Xcomb = combine_X(X)\n",
    "    Xminus = Xcomb[1]\n",
    "    Xplus = Xcomb[2]\n",
    "    \n",
    "    @trace(dbnmarginal(parent_vecs, Xminus, Xplus, deg_max), :X)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen.load_generated_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED X: (LEN=84,WID=20)\n",
      "XMINUS: (LEN=84,WID=20)\n",
      "XPLUS: (LEN=84,WID=20)\n"
     ]
    }
   ],
   "source": [
    "tr = Gen.simulate(full_model, (ts_vec, reference_dg, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "### Metropolis-Hastings over directed graphs\n",
    "\n",
    "Proposal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Proposal distribution for exploring the unconstrained space of\n",
    "directed graphs.\n",
    "\n",
    "`expected_indegree` guides the exploration -- if a vertex's in-degree\n",
    "is higher than this, then we are much more likely to remove an edge\n",
    "from one of its parents.\n",
    "\"\"\"\n",
    "@gen function digraph_proposal(tr, expected_indegree::Float64)\n",
    "    \n",
    "    G = copy(tr[:G])\n",
    "    ordered_vertices = sort(collect(G.vertices))\n",
    "    V = length(G.vertices)\n",
    "    \n",
    "    u_idx = @trace(Gen.uniform_discrete(1,V), :u_idx)\n",
    "    u = ordered_vertices[u_idx]\n",
    "    ordered_inneighbors = sort(collect(in_neighbors(G,u)))\n",
    "    in_deg = length(ordered_inneighbors)\n",
    "    \n",
    "    prob_remove = (1.0*in_deg / V) ^ (-1.0/log2(1.0*expected_indegree/V))\n",
    "    remove_edge = @trace(Gen.bernoulli(prob_remove), :remove_edge)\n",
    "    \n",
    "    if remove_edge\n",
    "        v_idx = @trace(Gen.uniform_discrete(1, in_deg), :v_idx)\n",
    "        v = ordered_inneighbors[v_idx]\n",
    "        remove_edge!(G, v, u)\n",
    "    else\n",
    "        \n",
    "        outneighbors = out_neighbors(G,u)\n",
    "        ordered_exc_outneighbors = sort(collect(setdiff(outneighbors, ordered_inneighbors)))\n",
    "        out_exc_deg = length(ordered_exc_outneighbors)\n",
    "        deg = length(union(outneighbors, ordered_inneighbors))\n",
    "        \n",
    "        prob_reverse = 1.0 * out_exc_deg / deg\n",
    "        reverse_edge = @trace(Gen.bernoulli(prob_reverse), :reverse_edge)\n",
    "        if reverse_edge\n",
    "            \n",
    "            v_idx = @trace(Gen.uniform_discrete(1, out_exc_deg), :v_idx)\n",
    "            v = ordered_exc_outneighbors[v_idx]\n",
    "            remove_edge!(G, u, v)\n",
    "            add_edge!(G, v, u)\n",
    "        else\n",
    "            nonparents = sort(collect(setdiff(G.vertices, ordered_inneighbors)))\n",
    "            len = length(nonparents)\n",
    "            v_idx = @trace(Gen.uniform_discrete(1,len), :v_idx)\n",
    "            v = nonparents[v_idx]\n",
    "            add_edge!(G, v, u)\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return G\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Involution function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "function digraph_involution(cur_tr, fwd_choices, fwd_ret, prop_args)\n",
    "    \n",
    "    # Update the trace \n",
    "    new_G = fwd_ret\n",
    "    old_G = cur_tr[:G]\n",
    "    update_choices = Gen.choicemap()\n",
    "    update_choices[:G] = new_G\n",
    "    new_tr, weight, retdiff, discard = Gen.update(cur_tr, Gen.get_args(cur_tr), (), update_choices)\n",
    "    \n",
    "    # figure out what has changed\n",
    "    fwd_u_idx = fwd_choices[:u_idx]\n",
    "    sorted_vertices = sort(collect(old_G.vertices))\n",
    "    fwd_u = sorted_vertices[fwd_u_idx]\n",
    "    fwd_v_idx = fwd_choices[:v_idx]\n",
    "    \n",
    "    # Deduce the correct backward choices\n",
    "    bwd_choices = Gen.choicemap()\n",
    "    if fwd_choices[:remove_edge] # an edge was removed -- we must add it back.\n",
    "        \n",
    "        fwd_parents = collect(in_neighbors(old_G, fwd_u))\n",
    "        fwd_v = sort(fwd_parents)[fwd_v_idx]\n",
    "        bwd_nonparents = sort(collect(setdiff(new_G.vertices,in_neighbors(new_G, fwd_u))))\n",
    "        bwd_v_idx = indexin([fwd_v], bwd_nonparents)[1]\n",
    "        \n",
    "        bwd_choices[:u_idx] = fwd_u_idx \n",
    "        bwd_choices[:remove_edge] = false\n",
    "        bwd_choices[:reverse_edge] = false\n",
    "        bwd_choices[:v_idx] = bwd_v_idx\n",
    "        \n",
    "    else\n",
    "        if fwd_choices[:reverse_edge] # an edge was reversed -- reverse it back.\n",
    "            \n",
    "            fwd_exc_outneighbors = sort(collect(setdiff(out_neighbors(old_G, fwd_u), in_neighbors(old_G, fwd_u))))\n",
    "            fwd_v = fwd_exc_outneighbors[fwd_v_idx]\n",
    "            bwd_u_idx = indexin([fwd_v], sorted_vertices)[1]\n",
    "            bwd_exc_outneighbors = sort(collect(setdiff(out_neighbors(new_G, fwd_v), in_neighbors(new_G, fwd_v))))\n",
    "            bwd_v_idx = indexin([fwd_u], bwd_exc_outneighbors)[1]\n",
    "            \n",
    "            bwd_choices[:u_idx] = bwd_u_idx\n",
    "            bwd_choices[:remove_edge] = false\n",
    "            bwd_choices[:reverse_edge] = true\n",
    "            bwd_choices[:v_idx] = bwd_v_idx\n",
    "            \n",
    "        else # an edge was added -- remove it.\n",
    "            \n",
    "            fwd_nonparents = sort(collect(setdiff(old_G.vertices, in_neighbors(old_G, fwd_u))))\n",
    "            fwd_v = fwd_nonparents[fwd_v_idx]\n",
    "            bwd_parents = sort(collect(in_neighbors(new_G, fwd_u)))\n",
    "            bwd_v_idx = indexin([fwd_v], bwd_parents)[1]\n",
    "            \n",
    "            bwd_choices[:u_idx] = fwd_u_idx\n",
    "            bwd_choices[:remove_edge] = true\n",
    "            bwd_choices[:v_idx] = bwd_v_idx\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return new_tr, bwd_choices, weight\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our inference program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inference_program (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function inference_program(model, model_args, choices, proposal, proposal_args, \n",
    "                           involution, n_samples, burnin, thinning)\n",
    "    \n",
    "    tr, _ = Gen.generate(model, model_args, choices)\n",
    "    \n",
    "    results = []\n",
    "    prop_count = 1\n",
    "    accepted = zeros(n_samples*thinning + burnin)\n",
    "    for i=1:burnin\n",
    "        tr, acc = Gen.mh(tr, proposal, proposal_args, involution)\n",
    "        accepted[prop_count] = acc\n",
    "        prop_count += 1\n",
    "    end\n",
    "    push!(results, tr[:G])\n",
    "    \n",
    "    for i=1:n_samples-1\n",
    "        for t=1:thinning\n",
    "            tr, acc = Gen.mh(tr, proposal, proposal_args, involution)\n",
    "            accepted[prop_count] = acc\n",
    "            prop_count += 1\n",
    "        end\n",
    "        push!(results, tr[:G])\n",
    "    end\n",
    "    \n",
    "    return results, accepted\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERFORM INFERENCE\n",
    "\n",
    "We condition the model on our data and sample from the posterior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED X: (LEN=84,WID=20)\n",
      "XMINUS: (LEN=84,WID=20)\n",
      "XPLUS: (LEN=84,WID=20)\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] Type at ./multidimensional.jl:564 [inlined]",
      " [2] Type at ./multidimensional.jl:566 [inlined]",
      " [3] to_index at ./indices.jl:264 [inlined]",
      " [4] to_index at ./indices.jl:247 [inlined]",
      " [5] to_indices at ./multidimensional.jl:645 [inlined]",
      " [6] to_indices at ./indices.jl:294 [inlined]",
      " [7] getindex at ./abstractarray.jl:981 [inlined]",
      " [8] in_neighbors(::DiGraph{Int64}, ::Int64) at /home/dmerrell/projects/graph-ppl/julia-project/DiGraph.jl:54",
      " [9] ##digraph_proposal#443(::Gen.GFAssessState, ::getfield(Main, Symbol(\"##StaticIRTrace_full_model#438\")), ::Float64) at ./In[48]:17",
      " [10] exec(::DynamicDSLFunction{Any}, ::Gen.GFAssessState, ::Tuple{getfield(Main, Symbol(\"##StaticIRTrace_full_model#438\")),Float64}) at /home/dmerrell/.julia/packages/Gen/muewn/src/dynamic/dynamic.jl:39",
      " [11] assess(::DynamicDSLFunction{Any}, ::Tuple{getfield(Main, Symbol(\"##StaticIRTrace_full_model#438\")),Float64}, ::DynamicChoiceMap) at /home/dmerrell/.julia/packages/Gen/muewn/src/dynamic/assess.jl:57",
      " [12] #metropolis_hastings#166(::Bool, ::typeof(metropolis_hastings), ::getfield(Main, Symbol(\"##StaticIRTrace_full_model#438\")), ::DynamicDSLFunction{Any}, ::Tuple{Float64}, ::typeof(digraph_involution)) at /home/dmerrell/.julia/packages/Gen/muewn/src/inference/mh.jl:68",
      " [13] metropolis_hastings(::getfield(Main, Symbol(\"##StaticIRTrace_full_model#438\")), ::DynamicDSLFunction{Any}, ::Tuple{Float64}, ::Function) at /home/dmerrell/.julia/packages/Gen/muewn/src/inference/mh.jl:66",
      " [14] inference_program(::getfield(Main, Symbol(\"##StaticGenFunction_full_model#439\")), ::Tuple{Array{Array{Float64,2},1},DiGraph{Int64},Int64}, ::DynamicChoiceMap, ::DynamicDSLFunction{Any}, ::Tuple{Float64}, ::Function, ::Int64, ::Int64, ::Int64) at ./In[50]:18",
      " [15] top-level scope at In[60]:4"
     ]
    }
   ],
   "source": [
    "observations = Gen.choicemap()\n",
    "observations[:X] = ts_vec\n",
    "observations[:lambda] = 3.0\n",
    "res, accepted = inference_program(full_model, (ts_vec, reference_dg, 1), observations,\n",
    "                        digraph_proposal, (2.0,), \n",
    "                        digraph_involution, \n",
    "                        100, 100000, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xminus, Xplus = combine_X(ts_vec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmat = construct_B([1; 2; 5; 9; 11; 13; 15], Xminus, 4);\n",
    "b2ic = construct_B2invconj([1; 2; 5; 9; 11; 13; 15], Xminus, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2ic_manual = bmat * inv(transpose(bmat) * bmat) * transpose(bmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = eigen(b2ic_manual);\n",
    "f.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's visualize our Metropolis-Hastings sampler. This is often the best way to check whether a sampler is working as expected.\n",
    "\n",
    "There's a one-to-one mapping between (i) directed graphs and (ii) bipartite undirected graphs. We'll visualize our directed graphs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function visualize_digraph(dg::DiGraph)\n",
    "    v = sort(collect(dg.vertices))\n",
    "    ys = length(v):-1:1\n",
    "    y_dict = Dict([vert => ys[i] for (i,vert) in enumerate(v)])\n",
    "    xs = [1.0, length(v)]\n",
    "    \n",
    "    p = Plots.plot(xlim=(0.0, length(v)+1), ylim=(0.0, length(v)+1), \n",
    "    legend=false, framestyle=:none, aspect_ratio=1.0)\n",
    "    Plots.yticks!(p, ys, v)\n",
    "    \n",
    "    for i=1:size(dg.edges)[1]\n",
    "        e = dg.edges[i,:]\n",
    "        Plots.plot!(p, xs, [y_dict[e[1]]; y_dict[e[2]]], c=:black)\n",
    "    end\n",
    "    for j=1:length(v)\n",
    "        Plots.scatter!(p, xs, [y_dict[v[j]]; y_dict[v[j]]], markersize=60.0/length(v), markercolor=:gray)\n",
    "        Plots.annotate!(p, xs[1]-0.2, y_dict[v[j]], Plots.text(v[j], :right, 10))\n",
    "        Plots.annotate!(p, xs[2]+0.2, y_dict[v[j]], Plots.text(v[j], :left, 10))\n",
    "    end\n",
    "    \n",
    "    return p\n",
    "end\n",
    "        \n",
    "function visualize_digraph_weighted(dg::DiGraph, weights::Dict)\n",
    "    v = sort(collect(dg.vertices))\n",
    "    ys = length(v):-1:1\n",
    "    y_dict = Dict([vert => ys[i] for (i,vert) in enumerate(v)])\n",
    "    xs = [1.0, length(v)]\n",
    "    \n",
    "    p = Plots.plot(xlim=(0.0, length(v)+1), ylim=(0.0, length(v)+1), \n",
    "    legend=false, framestyle=:none, aspect_ratio=1.0)\n",
    "    Plots.yticks!(p, ys, v)\n",
    "    \n",
    "    for (e, w) in weights\n",
    "        Plots.plot!(p, xs, [y_dict[e[1]]; y_dict[e[2]]], \n",
    "                    color=Plots.RGBA(0,0,0, w), lw=3.0)\n",
    "    end\n",
    "    for j=1:length(v)\n",
    "        Plots.scatter!(p, xs, [y_dict[v[j]]; y_dict[v[j]]], markersize=60.0/length(v), markercolor=:gray)\n",
    "        Plots.annotate!(p, xs[1]-0.2, y_dict[v[j]], Plots.text(v[j], :right, 10))\n",
    "        Plots.annotate!(p, xs[2]+0.2, y_dict[v[j]], Plots.text(v[j], :left, 10))\n",
    "    end\n",
    "    \n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = visualize_digraph(reference_dg)\n",
    "Plots.title!(p, \"Reference Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function animate_dbn_sampling(dg::DiGraph, model, model_args, proposal, proposal_args, \n",
    "                              involution, n_samples, thinning, title, gif_file_name)\n",
    "   \n",
    "    tr, _ = Gen.generate(model, model_args)\n",
    "    anim = @animate for i=1:n_samples\n",
    "        for t=1:thinning\n",
    "            tr, _ = Gen.metropolis_hastings(tr, proposal, proposal_args, involution)\n",
    "        end\n",
    "        p = visualize_digraph(tr[:G])\n",
    "        curtitle = replace(title, \"__SAMPLES__\"=>i)\n",
    "        Plots.title!(p, curtitle)\n",
    "        if i%thinning == 0\n",
    "            println(i, \" steps completed\")\n",
    "        end\n",
    "    end \n",
    "    gif(anim, gif_file_name)\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "function animate_dbn_sampling_density(dg::DiGraph, model, model_args, proposal, proposal_args, involution, \n",
    "                                      n_samples, thinning, median_weight, title, gif_file_name)\n",
    "    \n",
    "    tr, _ = Gen.generate(model, model_args)\n",
    "    count_dict = Dict()\n",
    "    \n",
    "    anim = @animate for i=1:n_samples\n",
    "        \n",
    "        for t=1:thinning\n",
    "            tr, _ = Gen.metropolis_hastings(tr, proposal, proposal_args, involution)\n",
    "        end\n",
    "        \n",
    "        G = tr[:G]\n",
    "        for j=1:size(G.edges)[1]\n",
    "            e = G.edges[j,:]\n",
    "            count_dict[e] = get(count_dict, e, 0) + 1\n",
    "        end\n",
    "        \n",
    "        weight_dict = Dict([e => (1.0*count/i)^(-1.0/log2(median_weight)) for (e, count) in count_dict])\n",
    "        #println(weight_dict)\n",
    "        p = visualize_digraph_weighted(G, weight_dict)\n",
    "        curtitle = replace(title, \"__SAMPLES__\"=>i)\n",
    "        Plots.title!(p, curtitle)\n",
    "    end\n",
    "       \n",
    "    fig = gif(anim, gif_file_name)\n",
    "    \n",
    "    return count_dict\n",
    "end\n",
    "   \n",
    "\n",
    "function graph_diff(new_g::DiGraph{T}, old_g::DiGraph{T}) where T\n",
    "    new_e = Set([new_g.edges[i,:] for i=1:size(new_g.edges)[1]])\n",
    "    old_e = Set([old_g.edges[i,:] for i=1:size(old_g.edges)[1]])\n",
    "    \n",
    "    new_exc = setdiff(new_e, old_e)\n",
    "    old_exc = setdiff(old_e, new_e)\n",
    "    if length(new_exc) > 0 && length(old_exc) == 0\n",
    "        return \"add\", first(new_exc)\n",
    "    elseif length(old_exc) > 0 && length(new_exc) == 0\n",
    "        return \"remove\", first(old_exc)\n",
    "    elseif length(old_exc) > 0 && length(new_exc) > 0\n",
    "        return \"reverse\", (first(old_exc), first(new_exc))\n",
    "    else\n",
    "        return \"none\", nothing\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function animate_dbn_exploration(dg::DiGraph, model, model_args, proposal, proposal_args, \n",
    "                                 involution, n_iterations, title, gif_file_name)\n",
    "    \n",
    "    v = sort(collect(dg.vertices))\n",
    "    ys = length(v):-1:1\n",
    "    y_dict = Dict([vert => ys[i] for (i,vert) in enumerate(v)])\n",
    "    xs = [1.0, length(v)]\n",
    "    \n",
    "    tr, _ = Gen.generate(model, model_args)\n",
    "    rejections = 0\n",
    "    anim = @animate for i=1:n_iterations\n",
    "        old_G = copy(tr[:G])\n",
    "        tr, acc = Gen.metropolis_hastings(tr, proposal, proposal_args, involution)\n",
    "        if !acc\n",
    "            rejections += 1\n",
    "        end\n",
    "        new_G = tr[:G]\n",
    "        p = visualize_digraph(new_G)\n",
    "        curtitle = replace(title, \"__STEPS__\"=>i)\n",
    "        curtitle = replace(curtitle, \"__REJECTIONS__\"=>rejections)\n",
    "        Plots.title!(p, curtitle)\n",
    "        diffstr, e = graph_diff(new_G, old_G)\n",
    "        if diffstr == \"add\"\n",
    "            plot!(p, xs, [y_dict[e[1]]; y_dict[e[2]]], color=:blue, lw=4.0)\n",
    "        elseif diffstr == \"remove\"\n",
    "            plot!(p, xs, [y_dict[e[1]]; y_dict[e[2]]], color=:red, lw=4.0)\n",
    "        elseif diffstr == \"reverse\"\n",
    "            plot!(p, xs, [y_dict[e[1][1]]; y_dict[e[1][2]]], color=:yellow, lw=4.0)\n",
    "            plot!(p, xs, [y_dict[e[2][1]]; y_dict[e[2][2]]], color=:yellow, lw=4.0)\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    fig = gif(anim, gif_file_name)\n",
    "    \n",
    "    return 1.0*rejections/n_iterations\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING BELOW..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function prior_model(lambda::Float64)\n",
    "    @trace(graphprior(lambda, reference_dg), :G)\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda = 3.0\n",
    "n_steps = 1000\n",
    "#med_indegs = [1.0; 2.0; 3.0; 3.7; 4.0; 5.0; 6.0]\n",
    "med_indegs = [0.25; 0.5; 0.75]\n",
    "rejection_rates = []\n",
    "for med_indeg in med_indegs\n",
    "    rr = animate_dbn_exploration(reference_dg, prior_model, (lambda,), digraph_proposal, (med_indeg,), \n",
    "                                 digraph_involution, n_steps,\n",
    "                                 \"Graph Exploration: __STEPS__ steps (__REJECTIONS__ rejected)\",\n",
    "                                 \"dg-explore-indeg$(med_indeg)-steps$(n_steps)-lambda$(lambda).gif\");\n",
    "    push!(rejection_rates, rr)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinnings = [100; 500; 1000]\n",
    "n_samples = 100\n",
    "for thinning in thinnings\n",
    "    animate_dbn_sampling(reference_dg, prior_model, (lambda,), digraph_proposal, (2.0,), \n",
    "                         digraph_involution, n_samples, thinning,\n",
    "                         \"Graph Prior Sampling: __SAMPLES__ samples\",\n",
    "                         \"dg-sample-samples$(n_samples)-thinning$(thinning)-lambda$(lambda).gif\"\n",
    "                        );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thinning in thinnings\n",
    "    animate_dbn_sampling_density(reference_dg, prior_model, (3.0,), digraph_proposal, (2.0,), \n",
    "                                 digraph_involution, n_samples, thinning, 0.50,\n",
    "                                 \"Graph Prior Edge Marginals: __SAMPLES__ samples\",\n",
    "                                 \"dg-density-samples$(n_samples)-thinning$(thinning)-lambda$(lambda).gif\");\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simple_sampling(dg, model, model_args, proposal, proposal_args,\n",
    "                         involution, n_samples, thinning)\n",
    "    \n",
    "    tr, _ = Gen.generate(model, model_args)\n",
    "    for i=1:n_samples\n",
    "        for t=1:thinning\n",
    "            tr, _ = Gen.metropolis_hastings(tr, proposal, proposal_args, involution)\n",
    "        end\n",
    "    end        \n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time begin\n",
    "    simple_sampling(reference_dg, dumb_model, (3.0,), digraph_proposal, (2.0,), digraph_involution,\n",
    "                       1000, 100)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Tuple([\"a\";\"b\";\"c\";\"d\";\"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fing in Combinatorics.combinations(v,3)\n",
    "    println(Tuple(fing))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand([0,1], 10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:,collect((1,2,3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v; [1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[v] = \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_cache = LRU{Vector{Int64},Float64}(maxsize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = get!(dumb_cache, [1;2;3;4]) do\n",
    "    return 1.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod(A,dims=2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot(transpose(A), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
